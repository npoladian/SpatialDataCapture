{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json as js\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return the name of a country when a nationality is provided \n",
    "# it is done to add a column with the country name to the imagegallery and merge it the the shapes of countries\n",
    "def CountryAssign(natvalue):\n",
    "    '''give a country name when a nationality is provided'''\n",
    "    try:\n",
    "        return countriesCap.loc[countriesCap.nationality == natvalue,'countryName'].tolist()[0]\n",
    "    except:\n",
    "        return np.nan\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reqding the file with the necessary data for the color vizualization\n",
    "imagegallery = pd.read_json('imagegallery.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageExploded = imagegallery.explode('NationalityCleaner').reindex(axis = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageExploded.NationalityCleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nationalities = imageExploded.NationalityCleaner.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nationalities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This file contains the one to one relation between country and nationality\n",
    "countriesCap = pd.read_json('CleanCountries.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and fillig the column with country values in the image gallery \n",
    "imageExploded['Country'] = imageExploded['NationalityCleaner'].apply(CountryAssign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageExploded = imageExploded.explode('Colors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageExploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the geometries of the countries\n",
    "countriesGeojson = gpd.read_file('countries.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countriesGeojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual inspection of the country names\n",
    "for i,x in enumerate(countries):\n",
    "    print(countries[i]['properties']['ADMIN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in imageExploded['Country'].unique():\n",
    "    if x in countriesGeojson.ADMIN.tolist():\n",
    "        continue\n",
    "    else:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these values of countries from the imagegallery did not have a match in the countries and are replaced:  \n",
    "United States : United States of America\n",
    "Serbia : Republic of Serbia\n",
    "Tanzania : United Republic of Tanzania\n",
    "Bahamas : The Bahamas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problemNats = ['United States','Serbia','Tanzania','Bahamas']\n",
    "replacementNats = ['United States of America','Republic of Serbia','United Republic of Tanzania','The Bahamas']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing the problematic nationalities:\n",
    "imageExploded['Country'] = imageExploded.Country.replace(problemNats,replacementNats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageExploded[imageExploded.Country == 'Republic of Serbia']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary stats \n",
    "imageExploded.groupby(['Country']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more convenient for the summary statistics\n",
    "colorMap = imageExploded[['Colors','Country']]\n",
    "# further add the decade for space time viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivoting to get the number of artworks by color by country;\n",
    "colorMap = pd.pivot_table(colorMap,index = ['Country'], columns='Colors',aggfunc=len, fill_value = 0)\n",
    "# Potentially add the decade for time visualizations\n",
    "# ,'Decade'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nats= pd.Series(colorMap.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorMap.index = range(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorMap['Country'] = nats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colorMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE GEOMETRY ASSIGNEMENT WORKED BU THERE WERE ISSUES WITH LOADING IT INTO MYSQL, SO TRYING ANOTHER METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = countriesGeojson.merge(colorMap,left_on='ADMIN',right_on = 'Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store data as shapefiles locally \n",
    "colormap.to_file('colormap.shp')\n",
    "colormap.to_file('colormap.geojson',driver='GeoJSON')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shapely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The next step is very important before loading the data in mysql. In its current state, the geopandas data frame can not be uploaded to my SQL. \n",
    "The trick to overcome this issue is to convert the geometry variable into WKT format for uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = colormap['geometry']\n",
    "#colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplifying the geometry to avoid having a heavy data set that would be difficult to visualize on the website. \n",
    "geom = geom.apply(lambda x: x.simplify(0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rounding the coordinates. \n",
    "geom = geom.apply(lambda x: shapely.wkt.dumps(x, rounding_precision=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap['geometry'] = geom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WRITING THE DATA TO JSON\n",
    "Saving the data locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = pd.read_json('Colormap.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap.to_json('colormap.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageExploded.reindex(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageExploded.to_json('imagegallery.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've finally reached a point where we can feel happy with the quality and format our data is in. It's now time to export that data to a database for future use.\n",
    "\n",
    "We'll use the Pandas SQL functionality to achieve this. Other more comprehensive SQL packages are available, but the Pandas tools make working between dataframes and SQL quite simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing Database Package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When accessing a database through an external script or application, you'll always need to ensure two things are done:\n",
    "\n",
    "1. Make sure the *package* is installed that allows your application (e.g. Python) to talk to your database (e.g. MySQL).\n",
    "\n",
    "2. Write a *connection string* within your application that tells it where the database is and how to connect to it. The syntax for this varies but the connection string always contains details of the database type, it's location, and the access credentials (e.g. username and password) needed for connection.\n",
    "\n",
    "**If you're working on your own machine, follow these steps to install the PyMySQL drivers.** This process is the same for any Python package being installed through Anaconda, but you'll find the majority of useful data science libraries come pre-installed. If you're using an ISD machine then unfortunately the installation will not persist outside of your current login, so you'll have to do this again every time you want to use the package.\n",
    "\n",
    "1. Open Anaconda Navigator and go to the Environments tab.\n",
    "\n",
    "2. Switch the drop down menu from Installed to All.\n",
    "\n",
    "3. Search for 'pymysql'.\n",
    "\n",
    "4. Click on the box on the left-hand side of the 'pymysql' entry, and hit 'Mark for Installation'.\n",
    "\n",
    "5. Click the Apply button in the bottom right corner, then wait for the installation to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the Database Connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pandas SQL connection builds on the SQLAlchemy library. To create the connection, we first load the SQLAlchemy library, and then create the connection. **The scripts for this are provided below, replace the access credentials where necessary, then run them.** You'll notice that the database location details (host and port numbers) have been provided for you.\n",
    "\n",
    "The connection settings provided here are for the MySQL database, but different settings are required for other database environments. More information on how to create these connections are provided here: http://docs.sqlalchemy.org/en/rel_0_9/core/engines.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the SQLAlchemy libraries\n",
    "import sqlalchemy as sqal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the connection string to the MySQL database\n",
    "# replace USERNAME and PASSWORD with your own credentials \n",
    "# LUO \n",
    "engineLUO = sqal.create_engine('mysql+pymysql://ucfnclu:halezomexa@dev.spatialdatacapture.org:3306/ucfnclu')\n",
    "# IVANN \n",
    "engine = sqal.create_engine('mysql+pymysql://ucfnisc:jeculifudo@dev.spatialdatacapture.org:3306/ucfnisc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make the connection to the database\n",
    "conn = engine.raw_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the Database from Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've created the connection to the database, we can write data directly to the database. This uses the `.to_sql()` function on the cleaned dataframe we wish to upload. Within this function we provide parameters the specify the database table name and connection details. The function helpfully creates the new \n",
    "\n",
    "**Check out the query below, and then run it.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'colormap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6ab11550db22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcolormap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'colormap'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mif_exists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'colormap' is not defined"
     ]
    }
   ],
   "source": [
    "# file for the map vizualisation\n",
    "colormap.to_sql('colormap',con=engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countries.to_sql('CountryColormap', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file for the image gallery\n",
    "imageExploded.to_sql('artworks', con=engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will want to check that the data has actually been correctly uploaded to the database. You can do this through MySQL Workbench, but it's good to know how to run SQL queries in from Python too. \n",
    "\n",
    "Here we will run a Pandas function that will call an SQL query and then place the results within a new dataframe. The function is called `.read_sql()` and just requires the SQL query, and the connection details. \n",
    "\n",
    "**Test this out below, filling the SQL query with a simply query on your new dataset. Once you've downloaded the data, check out the contents.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember to enter your SQL query in below\n",
    "reloadedColorMap = pd.read_sql('SELECT * FROM colormap', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloadedColorMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloadedartworks = pd.read_sql('SELECT * FROM artworks', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Decade</th>\n",
       "      <th>NationalityCleaner</th>\n",
       "      <th>Colors</th>\n",
       "      <th>ThumbnailURL</th>\n",
       "      <th>URL</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1890</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>rosybrown</td>\n",
       "      <td>http://www.moma.org/media/W1siZiIsIjU5NDA1Il0s...</td>\n",
       "      <td>http://www.moma.org/collection/works/2</td>\n",
       "      <td>Austria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1980</td>\n",
       "      <td>French</td>\n",
       "      <td>rosybrown</td>\n",
       "      <td>http://www.moma.org/media/W1siZiIsIjk3Il0sWyJw...</td>\n",
       "      <td>http://www.moma.org/collection/works/3</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1980</td>\n",
       "      <td>French</td>\n",
       "      <td>dimgray</td>\n",
       "      <td>http://www.moma.org/media/W1siZiIsIjk3Il0sWyJw...</td>\n",
       "      <td>http://www.moma.org/collection/works/3</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1900</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>wheat</td>\n",
       "      <td>http://www.moma.org/media/W1siZiIsIjk4Il0sWyJw...</td>\n",
       "      <td>http://www.moma.org/collection/works/4</td>\n",
       "      <td>Austria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1900</td>\n",
       "      <td>Austrian</td>\n",
       "      <td>rosybrown</td>\n",
       "      <td>http://www.moma.org/media/W1siZiIsIjk4Il0sWyJw...</td>\n",
       "      <td>http://www.moma.org/collection/works/4</td>\n",
       "      <td>Austria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177630</th>\n",
       "      <td>68692</td>\n",
       "      <td>1920</td>\n",
       "      <td>Russian</td>\n",
       "      <td>black</td>\n",
       "      <td>http://www.moma.org/media/W1siZiIsIjIyNzQ2MiJd...</td>\n",
       "      <td>http://www.moma.org/collection/works/409778</td>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177631</th>\n",
       "      <td>68693</td>\n",
       "      <td>1920</td>\n",
       "      <td>Russian</td>\n",
       "      <td>gainsboro</td>\n",
       "      <td>http://www.moma.org/media/W1siZiIsIjIyNzQ2MyJd...</td>\n",
       "      <td>http://www.moma.org/collection/works/409779</td>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177632</th>\n",
       "      <td>68694</td>\n",
       "      <td>1920</td>\n",
       "      <td>Russian</td>\n",
       "      <td>gainsboro</td>\n",
       "      <td>http://www.moma.org/media/W1siZiIsIjIyNzQ2NCJd...</td>\n",
       "      <td>http://www.moma.org/collection/works/409780</td>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177633</th>\n",
       "      <td>68695</td>\n",
       "      <td>1920</td>\n",
       "      <td>Russian</td>\n",
       "      <td>gainsboro</td>\n",
       "      <td>http://www.moma.org/media/W1siZiIsIjIyNzQ2NSJd...</td>\n",
       "      <td>http://www.moma.org/collection/works/409781</td>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177634</th>\n",
       "      <td>68696</td>\n",
       "      <td>1920</td>\n",
       "      <td>Russian</td>\n",
       "      <td>gainsboro</td>\n",
       "      <td>http://www.moma.org/media/W1siZiIsIjIyNzQ1OCJd...</td>\n",
       "      <td>http://www.moma.org/collection/works/409782</td>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177635 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index  Decade NationalityCleaner     Colors  \\\n",
       "0           0    1890           Austrian  rosybrown   \n",
       "1           1    1980             French  rosybrown   \n",
       "2           1    1980             French    dimgray   \n",
       "3           2    1900           Austrian      wheat   \n",
       "4           2    1900           Austrian  rosybrown   \n",
       "...       ...     ...                ...        ...   \n",
       "177630  68692    1920            Russian      black   \n",
       "177631  68693    1920            Russian  gainsboro   \n",
       "177632  68694    1920            Russian  gainsboro   \n",
       "177633  68695    1920            Russian  gainsboro   \n",
       "177634  68696    1920            Russian  gainsboro   \n",
       "\n",
       "                                             ThumbnailURL  \\\n",
       "0       http://www.moma.org/media/W1siZiIsIjU5NDA1Il0s...   \n",
       "1       http://www.moma.org/media/W1siZiIsIjk3Il0sWyJw...   \n",
       "2       http://www.moma.org/media/W1siZiIsIjk3Il0sWyJw...   \n",
       "3       http://www.moma.org/media/W1siZiIsIjk4Il0sWyJw...   \n",
       "4       http://www.moma.org/media/W1siZiIsIjk4Il0sWyJw...   \n",
       "...                                                   ...   \n",
       "177630  http://www.moma.org/media/W1siZiIsIjIyNzQ2MiJd...   \n",
       "177631  http://www.moma.org/media/W1siZiIsIjIyNzQ2MyJd...   \n",
       "177632  http://www.moma.org/media/W1siZiIsIjIyNzQ2NCJd...   \n",
       "177633  http://www.moma.org/media/W1siZiIsIjIyNzQ2NSJd...   \n",
       "177634  http://www.moma.org/media/W1siZiIsIjIyNzQ1OCJd...   \n",
       "\n",
       "                                                URL  Country  \n",
       "0            http://www.moma.org/collection/works/2  Austria  \n",
       "1            http://www.moma.org/collection/works/3   France  \n",
       "2            http://www.moma.org/collection/works/3   France  \n",
       "3            http://www.moma.org/collection/works/4  Austria  \n",
       "4            http://www.moma.org/collection/works/4  Austria  \n",
       "...                                             ...      ...  \n",
       "177630  http://www.moma.org/collection/works/409778   Russia  \n",
       "177631  http://www.moma.org/collection/works/409779   Russia  \n",
       "177632  http://www.moma.org/collection/works/409780   Russia  \n",
       "177633  http://www.moma.org/collection/works/409781   Russia  \n",
       "177634  http://www.moma.org/collection/works/409782   Russia  \n",
       "\n",
       "[177635 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloadedartworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "connLUO = engineLUO.raw_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloadedColorMap.to_sql('colormap',con=engineLUO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reloadedartworks.to_sql('artworks',con=engineLUO,if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Open up MySQL Workbench too and go and find your new dataset.**\n",
    "\n",
    "More information on how to access databases, insert data and query tables using SQL can be found the in documentation here: http://pandas.pydata.org/pandas-docs/stable/io.html#sql-queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well done for completing this tutorial. You should now have a good grounding in how to use Python and Pandas to load and clean data, and upload it to a database. We'll continue to use similar methods in the coming weeks. \n",
    "\n",
    "If you want to explore these methods further in the meantime, here are a few additional activities you might want to try:\n",
    "\n",
    "* Download a new dataset from London Air (http://www.londonair.org.uk/), go through the same process to fix up the data.\n",
    "\n",
    "* If you don't want to work with a new air pollution dataset, use the SQL connection to download only the *ratified* data. Explore how the NO, NO2 and NOX readings vary together over time, using plots and any other methods you feel like trying out (covariance and correlation, perhaps?).\n",
    "\n",
    "* Go and find another dataset to play with at the UK Open Datastore (http://data.gov.uk/data/search). There are some truly terrible, messy examples on there to get your teeth stuck into. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
